{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import numpy.matlib\n",
    "import numpy.linalg as la\n",
    "from numpy import inf\n",
    "import functools\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('function_words.csv','r')\n",
    "tmp = file.read()\n",
    "fwords = tmp.split('\\n')\n",
    "fwords = fwords[:-1]\n",
    "# Create a helper dictionary\n",
    "fwords_dict = {}\n",
    "for idx, word in enumerate(fwords):\n",
    "    fwords_dict[word] = idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Edit: modified to allow self-loops\n",
    "\n",
    "def functionWordWAN(sentence, fwords_dict, window_size, alpha):\n",
    "    wan = np.zeros((len(fwords_dict), len(fwords_dict)))\n",
    "    for idx, pivot in enumerate(sentence[:-1]): # don't include last word as pivot\n",
    "        if (not fwords_dict.get(pivot)):\n",
    "            continue\n",
    "        else:\n",
    "            sentence_slice = sentence[idx:(idx+window_size)]\n",
    "            for it, word in enumerate(sentence_slice[1:]): # don't include pivot word\n",
    "                if (fwords_dict.get(word)):\n",
    "#                     if (fwords_dict.get(word) != fwords_dict.get(pivot)): # no self loops\n",
    "                    r = fwords_dict.get(pivot)\n",
    "                    c = fwords_dict.get(word)\n",
    "                    wan[r-1,c-1] += pow(alpha,it+1)\n",
    "                           \n",
    "    return wan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeWAN(raw_wan):\n",
    "    sums = raw_wan.sum(axis=1)\n",
    "    sums = np.matlib.repmat(sums,len(fwords),1)\n",
    "    sums = sums.T\n",
    "    norm_wan = raw_wan / sums\n",
    "    norm_wan = np.nan_to_num(norm_wan) # Make sure nans from zero division are zeros\n",
    "    return norm_wan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateWANPair(snt1, snt2, window_size, alpha):\n",
    "    ret_data = {}\n",
    "    snt1_set = set(snt1)\n",
    "    snt2_set = set(snt2)\n",
    "    comp_set = snt1_set.union(snt2_set)\n",
    "    comp_dict = {}\n",
    "    # Generate the composite sentence dictionary\n",
    "    for idx, v in enumerate(comp_set):\n",
    "        comp_dict[v] = idx+1\n",
    "    \n",
    "    ret_data['snt1_wan'] = functionWordWAN(snt1, comp_dict, window_size, alpha)\n",
    "    ret_data['snt2_wan'] = functionWordWAN(snt2, comp_dict, window_size, alpha)\n",
    "    \n",
    "    return ret_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## A simple Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.75\n",
    "window_size = 10\n",
    "sentence1= ['the','cat','in','the','hat','bought','a','baseball','bat','i','am','happy']\n",
    "sentence2 = ['i','like','the','cat','in','the','hat','who','bought','a','baseball','bat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wan1 = functionWordWAN(sentence1, fwords_dict, window_size, alpha)\n",
    "wan2 = functionWordWAN(sentence2, fwords_dict, window_size, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_wan1 = normalizeWAN(wan1)\n",
    "norm_wan2 = normalizeWAN(wan2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Relative Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relativeEntropy(wan1, wan2):\n",
    "    # Return is a list containing 1 w.r.t 2, then 2 w.r.t. 1\n",
    "    data = {}\n",
    "    data['entropies'] = [0.0, 0.0]\n",
    "    \n",
    "    limiting1 = la.matrix_power(wan1, 50) # 25 selected as reasonable convergence value\n",
    "    limiting2 = la.matrix_power(wan2, 50)\n",
    "    \n",
    "    data['l1'] = limiting1\n",
    "    data['l2'] = limiting2\n",
    "    \n",
    "    # 1 w.r.t 2\n",
    "    imd = np.nan_to_num(np.divide(wan1,wan2)) # Set all nan's to zero (0/0)\n",
    "    imd[(imd == inf) | (imd == -inf)] = 0 # All infinities to 0 (sc alar/0)\n",
    "    log_imd = np.nan_to_num(np.log(imd))\n",
    "    log_imd[(log_imd == inf) | (log_imd == -inf)] = 0    \n",
    "    weights = functools.reduce(np.multiply, [limiting1, wan1, log_imd])\n",
    "    data['entropies'][0] = weights.sum()\n",
    "    \n",
    "    # 2 w.r.t 1\n",
    "    imd = np.nan_to_num(np.divide(wan2,wan1)) # Set all nan's to zero (0/0)\n",
    "    imd[(imd == inf) | (imd == -inf)] = 0 # All infinities to 0 (scalar/0)\n",
    "    log_imd = np.nan_to_num(np.log(imd))\n",
    "    log_imd[(log_imd == inf) | (log_imd == -inf)] = 0    \n",
    "    weights = functools.reduce(np.multiply, [limiting2, wan2, log_imd])\n",
    "    data['entropies'][1] = weights.sum()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = relativeEntropy(norm_wan1, norm_wan2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1133a4ba8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(data['l2'],interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entropies': [1.0080744990356447e-10, 9.9526899026165093e-14],\n",
       " 'l1': array([[  3.01533594e-13,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]),\n",
       " 'l2': array([[  3.26822495e-17,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
