{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP \n",
    "import TreeKernel as tk\n",
    "import TreeBuild as tb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _getNLPToks_(rawSentence):\n",
    "    try:\n",
    "        output = nlp.annotate(rawSentence, properties={\n",
    "            'annotators': 'tokenize,ssplit,pos,parse,depparse',\n",
    "            'outputFormat': 'json'\n",
    "        })\n",
    "    except UnicodeDecodeError:\n",
    "        sentence = unidecode(rawSentence)\n",
    "        output = nlp.annotate(sentence, properties={\n",
    "            'annotators': 'tokenize,ssplit,pos,parse,depparse',\n",
    "            'outputFormat': 'json'\n",
    "        })\n",
    "    dependencies = output['sentences'][0]['basicDependencies']\n",
    "    tokens = output['sentences'][0]['tokens']\n",
    "    parse = output['sentences'][0]['parse'].split(\"\\n\")\n",
    "    return {'deps':dependencies, 'toks':tokens, 'parse':parse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "Quote error on: %d 23989\n",
      "Quote error resolved\n",
      "Quote error on: %d 29784\n",
      "Quote error resolved\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "Quote error on: %d 247982\n",
      "Quote error resolved\n",
      "250000\n",
      "Quote error on: %d 257478\n",
      "Quote error resolved\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "Quote error on: %d 356092\n",
      "Quote error resolved\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "feature_vect = {}\n",
    "\n",
    "with open('input/stanfordData_train1.nlp', 'rb') as handle:\n",
    "    count = 0\n",
    "    while True:\n",
    "        if (count % 10000 == 0):\n",
    "            print(count)\n",
    "\n",
    "        try:\n",
    "            unit = pickle.load(handle)\n",
    "            # ST Syntax score\n",
    "            (rscore, nscore) = tk._CollinsDuffy_(unit['q1']['parse'], unit['q2']['parse'], 1, 1, 0)\n",
    "            feature_vect[unit['id']] = {'id':unit['id'], 'cdNorm':nscore, 'cdRaw':rscore}\n",
    "            \n",
    "        except EOFError:\n",
    "            break\n",
    "        except:\n",
    "            print(\"Quote error on: %d\", unit['id'])\n",
    "            \n",
    "            q1_stanford = _getNLPToks_(unit['q1']['raw'].replace('\"','').replace(\"'\",''))\n",
    "            q2_stanford = _getNLPToks_(unit['q2']['raw'].replace('\"','').replace(\"'\",''))\n",
    "\n",
    "            tree_1 = tb.tree()\n",
    "            tree_2 = tb.tree()\n",
    "\n",
    "            # Generate a tree structure\n",
    "            tb._generateTree_(q1_stanford['parse'], tree_1)\n",
    "            tb._generateTree_(q2_stanford['parse'], tree_2)\n",
    "\n",
    "            # Flip the trees\n",
    "            tb._flipTree_(tree_1)\n",
    "            tb._flipTree_(tree_2)\n",
    "\n",
    "            (rscore, nscore) = tk._CollinsDuffy_(tree_1,\n",
    "                                                 tree_2,\n",
    "                                                 1, 1, 0)\n",
    "            \n",
    "            feature_vect[unit['id']] = {'id':unit['id'], 'cdNorm':nscore, 'cdRaw':rscore}\n",
    "            print(\"Quote error resolved\")\n",
    "            pass \n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_feature = pd.DataFrame.from_dict(feature_vect)\n",
    "df_feature = df_feature.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_feature[['id']] = df_feature[['id']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_feature.to_csv('input/collins_duffy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parser_f() got an unexpected keyword argument 'path_or_buf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-831d09119f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input/train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: parser_f() got an unexpected keyword argument 'path_or_buf'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Tomorrow is my exam, but I don't care because a single sheet of paper can't decide my future\". Isn't this very easy to say?\n",
      "Tomorrow is my exam, but I dont care because a single sheet of paper cant decide my future. Isnt this very easy to say?\n",
      "7.0\n",
      "0.264575131106\n",
      "(0, {'indent': 0, 'childrenTok': 'S', 'parid': -1, 'posOrTok': 'ROOT', 'children': [1], 'curid': 0})\n",
      "(1, {'indent': 2, 'childrenTok': ['S', 'CC', 'S'], 'parid': 0, 'posOrTok': 'S', 'children': [2, 9, 11], 'curid': 1})\n",
      "(2, {'indent': 4, 'childrenTok': ['NP', 'VP'], 'parid': 1, 'posOrTok': 'S', 'children': [3, 6], 'curid': 2})\n",
      "(3, {'indent': 6, 'childrenTok': ['NN'], 'parid': 2, 'posOrTok': 'NP', 'children': [4], 'curid': 3})\n",
      "(4, {'indent': 8, 'childrenTok': ['Tomorrow'], 'parid': 3, 'posOrTok': 'NN', 'children': [5], 'curid': 4})\n",
      "(5, {'indent': 8, 'childrenTok': [], 'parid': 4, 'posOrTok': 'Tomorrow', 'children': [], 'curid': 5})\n",
      "(6, {'indent': 6, 'childrenTok': ['VBZ'], 'parid': 2, 'posOrTok': 'VP', 'children': [7], 'curid': 6})\n",
      "(7, {'indent': 8, 'childrenTok': ['is'], 'parid': 6, 'posOrTok': 'VBZ', 'children': [8], 'curid': 7})\n",
      "(8, {'indent': 8, 'childrenTok': [], 'parid': 7, 'posOrTok': 'is', 'children': [], 'curid': 8})\n",
      "(9, {'indent': 6, 'childrenTok': ['but'], 'parid': 1, 'posOrTok': 'CC', 'children': [10], 'curid': 9})\n",
      "(10, {'indent': 6, 'childrenTok': [], 'parid': 9, 'posOrTok': 'but', 'children': [], 'curid': 10})\n",
      "(11, {'indent': 4, 'childrenTok': ['NP', 'VP'], 'parid': 1, 'posOrTok': 'S', 'children': [12, 15], 'curid': 11})\n",
      "(12, {'indent': 6, 'childrenTok': ['PRP'], 'parid': 11, 'posOrTok': 'NP', 'children': [13], 'curid': 12})\n",
      "(13, {'indent': 8, 'childrenTok': ['I'], 'parid': 12, 'posOrTok': 'PRP', 'children': [14], 'curid': 13})\n",
      "(14, {'indent': 8, 'childrenTok': [], 'parid': 13, 'posOrTok': 'I', 'children': [], 'curid': 14})\n",
      "(15, {'indent': 6, 'childrenTok': ['VBP', 'NP', 'SBAR'], 'parid': 11, 'posOrTok': 'VP', 'children': [16, 18, 21], 'curid': 15})\n",
      "(16, {'indent': 8, 'childrenTok': ['dont'], 'parid': 15, 'posOrTok': 'VBP', 'children': [17], 'curid': 16})\n",
      "(17, {'indent': 8, 'childrenTok': [], 'parid': 16, 'posOrTok': 'dont', 'children': [], 'curid': 17})\n",
      "(18, {'indent': 8, 'childrenTok': ['NN'], 'parid': 15, 'posOrTok': 'NP', 'children': [19], 'curid': 18})\n",
      "(19, {'indent': 10, 'childrenTok': ['care'], 'parid': 18, 'posOrTok': 'NN', 'children': [20], 'curid': 19})\n",
      "(20, {'indent': 10, 'childrenTok': [], 'parid': 19, 'posOrTok': 'care', 'children': [], 'curid': 20})\n",
      "(21, {'indent': 8, 'childrenTok': ['IN', 'NP'], 'parid': 15, 'posOrTok': 'SBAR', 'children': [22, 24], 'curid': 21})\n",
      "(22, {'indent': 10, 'childrenTok': ['because'], 'parid': 21, 'posOrTok': 'IN', 'children': [23], 'curid': 22})\n",
      "(23, {'indent': 10, 'childrenTok': [], 'parid': 22, 'posOrTok': 'because', 'children': [], 'curid': 23})\n",
      "(24, {'indent': 10, 'childrenTok': ['NP', 'PP'], 'parid': 21, 'posOrTok': 'NP', 'children': [25, 32], 'curid': 24})\n",
      "(25, {'indent': 12, 'childrenTok': ['DT', 'JJ', 'NN'], 'parid': 24, 'posOrTok': 'NP', 'children': [26, 28, 30], 'curid': 25})\n",
      "(26, {'indent': 14, 'childrenTok': ['a'], 'parid': 25, 'posOrTok': 'DT', 'children': [27], 'curid': 26})\n",
      "(27, {'indent': 14, 'childrenTok': [], 'parid': 26, 'posOrTok': 'a', 'children': [], 'curid': 27})\n",
      "(28, {'indent': 14, 'childrenTok': ['single'], 'parid': 25, 'posOrTok': 'JJ', 'children': [29], 'curid': 28})\n",
      "(29, {'indent': 14, 'childrenTok': [], 'parid': 28, 'posOrTok': 'single', 'children': [], 'curid': 29})\n",
      "(30, {'indent': 14, 'childrenTok': ['sheet'], 'parid': 25, 'posOrTok': 'NN', 'children': [31], 'curid': 30})\n",
      "(31, {'indent': 14, 'childrenTok': [], 'parid': 30, 'posOrTok': 'sheet', 'children': [], 'curid': 31})\n",
      "(32, {'indent': 12, 'childrenTok': ['IN', 'S'], 'parid': 24, 'posOrTok': 'PP', 'children': [33, 35], 'curid': 32})\n",
      "(33, {'indent': 14, 'childrenTok': ['of'], 'parid': 32, 'posOrTok': 'IN', 'children': [34], 'curid': 33})\n",
      "(34, {'indent': 14, 'childrenTok': [], 'parid': 33, 'posOrTok': 'of', 'children': [], 'curid': 34})\n",
      "(35, {'indent': 14, 'childrenTok': ['VP'], 'parid': 32, 'posOrTok': 'S', 'children': [36], 'curid': 35})\n",
      "(36, {'indent': 16, 'childrenTok': ['NN', 'SBAR'], 'parid': 35, 'posOrTok': 'VP', 'children': [37, 39], 'curid': 36})\n",
      "(37, {'indent': 18, 'childrenTok': ['paper'], 'parid': 36, 'posOrTok': 'NN', 'children': [38], 'curid': 37})\n",
      "(38, {'indent': 18, 'childrenTok': [], 'parid': 37, 'posOrTok': 'paper', 'children': [], 'curid': 38})\n",
      "(39, {'indent': 18, 'childrenTok': ['S'], 'parid': 36, 'posOrTok': 'SBAR', 'children': [40], 'curid': 39})\n",
      "(40, {'indent': 20, 'childrenTok': ['JJ', 'VP'], 'parid': 39, 'posOrTok': 'S', 'children': [41, 43], 'curid': 40})\n",
      "(41, {'indent': 22, 'childrenTok': ['cant'], 'parid': 40, 'posOrTok': 'JJ', 'children': [42], 'curid': 41})\n",
      "(42, {'indent': 22, 'childrenTok': [], 'parid': 41, 'posOrTok': 'cant', 'children': [], 'curid': 42})\n",
      "(43, {'indent': 22, 'childrenTok': ['VB'], 'parid': 40, 'posOrTok': 'VP', 'children': [44], 'curid': 43})\n",
      "(44, {'indent': 24, 'childrenTok': ['decide'], 'parid': 43, 'posOrTok': 'VB', 'children': [45], 'curid': 44})\n",
      "(45, {'indent': 24, 'childrenTok': [], 'parid': 44, 'posOrTok': 'decide', 'children': [], 'curid': 45})\n"
     ]
    }
   ],
   "source": [
    "qsample = df_train.ix[23989]\n",
    "\n",
    "print(qsample['question1'])\n",
    "print(qsample['question1'].replace('\"','').replace(\"'\",''))\n",
    "\n",
    "q1_stanford = _getNLPToks_(qsample['question1'].replace('\"','').replace(\"'\",''))\n",
    "q2_stanford = _getNLPToks_(qsample['question2'])\n",
    "\n",
    "tree_1 = tb.tree()\n",
    "tree_2 = tb.tree()\n",
    "\n",
    "# Generate a tree structure\n",
    "tb._generateTree_(q1_stanford['parse'], tree_1)\n",
    "tb._generateTree_(q2_stanford['parse'], tree_2)\n",
    "\n",
    "# Flip the trees\n",
    "tb._flipTree_(tree_1)\n",
    "tb._flipTree_(tree_2)\n",
    "\n",
    "(rscore, nscore) = tk._CollinsDuffy_(tree_1, tree_2, 1, 1, 0) \n",
    "print(rscore)\n",
    "print(nscore)\n",
    "\n",
    "for i in tree_1.items():\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc570ea3b009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_vect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_vect' is not defined"
     ]
    }
   ],
   "source": [
    "feature_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
