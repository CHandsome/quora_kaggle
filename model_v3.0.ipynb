{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "sample_submission.csv\n",
      "stanfordData_train1.nlp\n",
      "test.csv\n",
      "test_collins_duffy\n",
      "test_dean\n",
      "train.csv\n",
      "train_collins_duffy\n",
      "train_dean\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "import matplotlib.pylab as plt\n",
    "from numpy import linalg as LA\n",
    "%matplotlib\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform, Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of base training File =  (404290, 6)\n",
      "Shape of base training data after cleaning =  (404290, 6)\n",
      "Shape of base training File =  (2345796, 3)\n",
      "Shape of base training data after cleaning =  (2345796, 3)\n",
      "['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_data(path_to_file):\n",
    "    df = pd.read_csv(path_to_file)\n",
    "    print (\"Shape of base training File = \", df.shape)\n",
    "    print(\"Shape of base training data after cleaning = \", df.shape)\n",
    "    return df\n",
    "\n",
    "df_train = read_data(\"input/train.csv\")\n",
    "df_submit = read_data(\"input/test.csv\")\n",
    "\n",
    "# Print the column names\n",
    "print (df_train.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Collins Duffy Training Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_1e-1_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_1e-1_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_1e-2_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_1e-2_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_1e0_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_1e0_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_2e-1_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_2e-1_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_5e-1_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_5e-1_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_5e-2_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_5e-2_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_8e-1_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/train_collins_duffy/sd_8e-1_st.csv\n"
     ]
    }
   ],
   "source": [
    "df_features = None\n",
    "flip = True\n",
    "base = 'input/train_collins_duffy/'\n",
    "count = 0\n",
    "for filename in os.listdir(base):\n",
    "    if filename.endswith(\".csv\"): \n",
    "        tmpFrame = pd.read_csv(os.path.join(os.getcwd(), base, filename))\n",
    "        print(os.path.join(os.getcwd(), base, filename))\n",
    "        tmpFrame = tmpFrame.rename(columns={'cdNorm_st': filename.replace(\".csv\",\"\")})\n",
    "        if flip:\n",
    "            df_features = tmpFrame\n",
    "            flip = False\n",
    "        else:\n",
    "            df_features = df_features.merge(tmpFrame,how='inner',on='id')\n",
    "        count+=1\n",
    "        continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Collins Duffy Test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_1e-1_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_1e-1_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_1e-2_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_1e-2_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_1e0_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_1e0_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_2e-1_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_2e-1_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_5e-1_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_5e-1_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_5e-2_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_5e-2_st.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_8e-1_sst.csv\n",
      "/Users/deanfulgoni/Documents/Code/quora_kaggle/input/test_collins_duffy/sd_8e-1_st.csv\n"
     ]
    }
   ],
   "source": [
    "df_features_test = None\n",
    "flip = True\n",
    "base = 'input/test_collins_duffy/'\n",
    "count = 0\n",
    "for filename in os.listdir(base):\n",
    "    if filename.endswith(\".csv\"): \n",
    "        tmpFrame = pd.read_csv(os.path.join(os.getcwd(), base, filename))\n",
    "        print(os.path.join(os.getcwd(), base, filename))\n",
    "        tmpFrame = tmpFrame.rename(columns={'cdNorm_st': filename.replace(\".csv\",\"\")})\n",
    "        if flip:\n",
    "            df_features_test = tmpFrame\n",
    "            flip = False\n",
    "        else:\n",
    "            df_features_test = df_features_test.merge(tmpFrame,how='inner',on='id')\n",
    "        count+=1\n",
    "        continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Dean's Semantic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_semantic = pd.read_csv('input/train_dean/dean_train_features.csv')\n",
    "df_semantic.drop('is_duplicate',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, auc, roc_curve, log_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Read in the pre-built features for the training set\n",
    "df_train = df_train.merge(df_features,how='inner',on='id')\n",
    "df_train = df_train.merge(df_semantic,how='inner',on='id')\n",
    "\n",
    "# Methodology - fill with zeroes Any row that crashed the Stanford CoreNLP parser must have been empty string\n",
    "df_train.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
       "       'sd_1e-1_sst', 'sd_1e-1_st', 'sd_1e-2_sst', 'sd_1e-2_st', 'sd_1e0_sst',\n",
       "       'sd_1e0_st', 'sd_2e-1_sst', 'sd_2e-1_st', 'sd_5e-1_sst', 'sd_5e-1_st',\n",
       "       'sd_5e-2_sst', 'sd_5e-2_st', 'sd_8e-1_sst', 'sd_8e-1_st', 'S_sem_sim',\n",
       "       'T_sem_sim', 'sem_sim', 'S_unmatch_n', 'T_unmatch_n', 'S_unmatch_n_p',\n",
       "       'T_unmatch_n_p', 'S_unmatch_a', 'T_unmatch_a', 'S_unmatch_a_p',\n",
       "       'T_unmatch_a_p', 'S_unmatch_v', 'T_unmatch_v', 'S_unmatch_v_p',\n",
       "       'T_unmatch_v_p', 'S_unmatch_pp', 'T_unmatch_pp', 'S_unmatch_pp_p',\n",
       "       'T_unmatch_pp_p', 'S_unmatch_wp', 'T_unmatch_wp', 'S_unmatch_wp_p',\n",
       "       'T_unmatch_wp_p', 'S_unmatch_num', 'T_unmatch_num', 'S_unmatch_num_p',\n",
       "       'T_unmatch_num_p', 'S_unmatch_ner', 'T_unmatch_ner', 'len_dif',\n",
       "       'len_dif_p'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding More Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Question Lengths\n",
    "# df_train['q1len'] = df_train['question1'].str.len()\n",
    "# df_train['q2len'] = df_train['question2'].str.len()\n",
    "\n",
    "# df_submit['q1len'] = df_submit['question1'].str.len()\n",
    "# df_submit['q2len'] = df_submit['question2'].str.len()\n",
    "\n",
    "# # Normalized Word Share\n",
    "# def number_of_words(row):\n",
    "#     try:\n",
    "#         nwords = len(row.split(\" \"))\n",
    "#         return nwords\n",
    "#     except:\n",
    "#         return 0\n",
    "\n",
    "# # Normalized Word Share\n",
    "# def normalized_word_share(row):\n",
    "#     try:\n",
    "#         w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "#         w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "#         return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
    "#     except:\n",
    "#         return 0\n",
    "\n",
    "# def word_diff(row):\n",
    "#     try:\n",
    "#         diff = abs(row['q1_n_words']-row['q2_n_words'])\n",
    "#         return diff\n",
    "#     except:\n",
    "#         return 0\n",
    "    \n",
    "# # Number of Words\n",
    "# df_train['q1_n_words'] = df_train['question1'].apply(number_of_words)\n",
    "# df_train['q2_n_words'] = df_train['question2'].apply(number_of_words)\n",
    "\n",
    "# df_submit['q1_n_words'] = df_submit['question1'].apply(number_of_words)\n",
    "# df_submit['q2_n_words'] = df_submit['question2'].apply(number_of_words)\n",
    "    \n",
    "# # Normalized Word share\n",
    "# df_train['word_share'] = df_train.apply(normalized_word_share, axis=1)\n",
    "# df_submit['word_share'] = df_submit.apply(normalized_word_share, axis=1)\n",
    "\n",
    "# df_train['word_diff'] = df_train.apply(word_diff, axis=1)\n",
    "# df_submit['word_diff'] = df_submit.apply(word_diff, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select_cols = list(df_train.columns[6:])\n",
    "df_y = df_train['is_duplicate']\n",
    "df_X = df_train[select_cols].copy()\n",
    "\n",
    "df_X.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404282, 45), (404282,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_X.values\n",
    "y = df_y.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.10, random_state=24)\n",
    "\n",
    "X_train_mat = X_train.values\n",
    "y_train_mat = y_train.values\n",
    "\n",
    "X_train_mat = MinMaxScaler().fit_transform(X_train_mat)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(chi2, k=3)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "column_indexer = selector.get_support()\n",
    "X_df_selected = df_X.loc[:,column_indexer]\n",
    "X_df_selected.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(df_X[df_train['is_duplicate'] == 0]['sem_sim'], bins=20, normed=False, label='Not Duplicate')\n",
    "plt.hist(df_X[df_train['is_duplicate'] == 1]['sem_sim'], bins=20, normed=False, alpha=0.6, label='Duplicate')\n",
    "plt.legend()\n",
    "plt.title('Label Distribution Over Semantic Similarity of Aligned Words', fontsize=15)\n",
    "plt.xlabel('Normalized Percentage of Aligned Pairs', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(df_X[df_train['is_duplicate'] == 0]['sd_1e-1_sst'], bins=20, normed=False, label='Not Duplicate')\n",
    "plt.hist(df_X[df_train['is_duplicate'] == 1]['sd_1e-1_sst'], bins=20, normed=False, alpha=0.6, label='Duplicate')\n",
    "plt.legend()\n",
    "plt.title('Label Distribution Over SST Tree Kernel, Lambda = 0.1', fontsize=15)\n",
    "plt.xlabel('Normalized Score', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(df_X[df_train['is_duplicate'] == 0]['S_unmatch_ner'], bins=20, normed=False, label='Not Duplicate')\n",
    "plt.hist(df_X[df_train['is_duplicate'] == 1]['S_unmatch_ner'], bins=20, normed=False, alpha=0.6, label='Duplicate')\n",
    "plt.legend()\n",
    "plt.title('Label Distribution Over Number Unmatched Named Entities', fontsize=15)\n",
    "plt.xlabel('Number Unmatched Named Entities (cutoff=3)', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grid = {\n",
    " #   'C': [1e-3, 1e0, 1e1],\n",
    "#    'penalty': ['l1', 'l2']\n",
    "#}\n",
    "#logreg_cv = GridSearchCV(logreg_clf, grid, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Print the best cross-validation parameters\n",
    "#print(logreg_cv.best_params_)\n",
    "#print(logreg_cv.best_estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Best was found to be l2 penalty (default) and C=10\n",
    "logreg_clf = LogisticRegression(C=10)\n",
    "y_pred_logreg = cross_val_predict(logreg_clf, X, y)\n",
    "log_loss_scores = cross_val_score(logreg_clf, X, y, scoring='neg_log_loss')\n",
    "ll = log_loss_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y, y_pred_logreg)\n",
    "prec = precision_score(y, y_pred_logreg)\n",
    "recall = recall_score(y, y_pred_logreg)\n",
    "f1 = f1_score(y, y_pred_logreg)\n",
    "print(acc, prec, recall, f1)\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_features': [5, 10, 20]\n",
    "}\n",
    "rf_cv = GridSearchCV(rf_clf, grid, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
    "rf_cv.fit(X_train_mat, y_train_mat)\n",
    "print(rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=200, max_features=5)\n",
    "y_pred_rf = cross_val_predict(rf_clf, X, y)\n",
    "log_loss_scores = cross_val_score(rf_clf, X, y, scoring='neg_log_loss')\n",
    "ll = log_loss_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y, y_pred_rf)\n",
    "prec = precision_score(y, y_pred_rf)\n",
    "recall = recall_score(y, y_pred_rf)\n",
    "f1 = f1_score(y, y_pred_rf)\n",
    "print(acc, prec, recall, f1)\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = ['r', 'g', 'b', 'y', 'k', 'c', 'm', 'brown', 'r']\n",
    "lw = 1\n",
    "Cs = [1e-6, 1e-3, 1e0, 1e1]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for different classifiers')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "labels = []\n",
    "for idx, C in enumerate(Cs):\n",
    "    clf = LogisticRegression(C = C)\n",
    "    clf.fit(X_train_mat, y_train_mat)\n",
    "    print(\"C: {}, parameters {} and intercept {}\".format(C, clf.coef_, clf.intercept_))\n",
    "    fpr, tpr, _ = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=lw, color=colors[idx])\n",
    "    labels.append(\"C: {}, AUC = {}\".format(C, np.round(roc_auc, 4)))\n",
    "\n",
    "plt.legend(['random AUC = 0.5'] + labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr, re, _ = precision_recall_curve(y_test, cv.best_estimator_.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(re, pr)\n",
    "plt.title('PR Curve (AUC {})'.format(auc(re, pr)))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in test set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_semantic_test = pd.read_csv('input/test_dean/dean_test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the pre-built features for the test set\n",
    "df_submit = df_submit.merge(df_features_test,how='left',left_on='test_id',right_on='id')\n",
    "# df_train = df_train.merge(df_semantic,how='inner',on='id')\n",
    "df_submit.drop(['id'],inplace=True,axis=1)\n",
    "df_submit = df_submit.merge(df_semantic_test,how='left',left_on='test_id',right_on='id')\n",
    "df_submit.drop(['id'],inplace=True,axis=1)\n",
    "\n",
    "# Methodology - fill with zeroes Any row that crashed the Stanford CoreNLP parser must have been empty string\n",
    "df_submit.fillna(value=0, inplace=True)\n",
    "\n",
    "X_test_set = df_submit[df_submit.columns[3:]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions for Logistic Regression and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg_clf = LogisticRegression(C=10)\n",
    "logreg_clf.fit(X, y)\n",
    "probs = logreg_clf.predict_proba(X_test_set)\n",
    "df_submit['is_duplicate'] = probs[:,1]\n",
    "df_final_submit = df_submit[['test_id','is_duplicate']]\n",
    "df_final_submit.to_csv(\"submissions/lr_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=200, max_features=5)\n",
    "rf_clf.fit(X, y)\n",
    "probs = rf_clf.predict_proba(X_test_set)\n",
    "df_submit['is_duplicate'] = probs[:,1]\n",
    "df_final_submit = df_submit[['test_id','is_duplicate']]\n",
    "df_final_submit.to_csv(\"submissions/rf_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
