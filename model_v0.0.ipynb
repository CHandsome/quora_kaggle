{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "cosine_sim_feaure.gz\n",
      "sample.rtf\n",
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "train_with_cosine_v0.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "import matplotlib.pylab as plt\n",
    "from numpy import linalg as LA\n",
    "%matplotlib\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform, Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of base training File =  (404290, 6)\n",
      "Shape of base training data after cleaning =  (404288, 6)\n",
      "Shape of base training File =  (2345796, 3)\n",
      "Shape of base training data after cleaning =  (2345790, 3)\n",
      "['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_data(path_to_file):\n",
    "    df = pd.read_csv(path_to_file)\n",
    "    print (\"Shape of base training File = \", df.shape)\n",
    "    # Remove missing values and duplicates from training data\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"Shape of base training data after cleaning = \", df.shape)\n",
    "    return df\n",
    "\n",
    "df_train = read_data(\"input/train.csv\")\n",
    "# df_train, df_test = train_test_split(df, test_size = 0.10)\n",
    "# df_train = df_train.reset_index(drop=True)\n",
    "# df_train = df_train.reset_index()\n",
    "# df_train = df_train.rename(columns = {'index':'mat_idx'})\n",
    "\n",
    "df_submit = read_data(\"input/test.csv\")\n",
    "df_submit = df_submit.reset_index(drop=True)\n",
    "df_submit = df_submit.reset_index()\n",
    "df_submit = df_submit.rename(columns = {'index': 'mat_idx'})\n",
    "\n",
    "\n",
    "# Print the column names\n",
    "print (df_train.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words feature\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words feature\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "# Use this as \"stop_words\" arg if include stopwords\n",
    "# stopwords.words('english')\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "# For now assume stop-words are not discounted. No terms are thresholded. \n",
    "vectorizer = CountVectorizer(analyzer = stemmed_words,   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             ngram_range = (1,2), \\\n",
    "                             max_features = 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Set Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# cos_feature_vec = np.zeros((df_train.shape[0],1))\n",
    "\n",
    "def gen_cosine_sim(s1, s2, vectorizer):\n",
    "    try:\n",
    "        features = vectorizer.fit_transform([s1, s2])\n",
    "        similarities = cosine_similarity(features)\n",
    "        return similarities[0,1]\n",
    "    except:\n",
    "        return 0.5 # May need to change for normalization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optionally write the cosine similarity feature vector to compressed file for storage\n",
    "# np.savetxt(\"input/cosine_sim_feaure.gz\",cos_feature_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Feature Generated...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((323430, 1), (80858, 1), (323430,), (80858,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv(\"input/train_with_cosine_v0.csv\")\n",
    "except OSError:\n",
    "    df_train['cos_sim'] = df_train.apply(lambda row: gen_cosine_sim(row['question1'],\n",
    "                                                                    row['question2'],\n",
    "                                                                    vectorizer), axis=1)\n",
    "\n",
    "    \n",
    "# cos_feature_vec.T[0].tolist()\n",
    "\n",
    "print(\"Cosine Similarity Feature Generated...\")\n",
    "\n",
    "scaler = MinMaxScaler().fit(df_train[['cos_sim']])\n",
    "X = scaler.transform(df_train[['cos_sim']])\n",
    "\n",
    "y = df_train['is_duplicate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=37)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [1e-06, 0.001, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "grid = {\n",
    "    'C': [1e-6, 1e-3, 1e0],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "cv = GridSearchCV(clf, grid, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Mean validation neg log loss: -0.693 (std: 0.000) - {'penalty': 'l1', 'C': 1e-06}\n",
      "5. Mean validation neg log loss: -0.690 (std: 0.000) - {'penalty': 'l2', 'C': 1e-06}\n",
      "3. Mean validation neg log loss: -0.594 (std: 0.001) - {'penalty': 'l1', 'C': 0.001}\n",
      "4. Mean validation neg log loss: -0.600 (std: 0.001) - {'penalty': 'l2', 'C': 0.001}\n",
      "2. Mean validation neg log loss: -0.592 (std: 0.001) - {'penalty': 'l1', 'C': 1.0}\n",
      "1. Mean validation neg log loss: -0.592 (std: 0.001) - {'penalty': 'l2', 'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(cv.cv_results_['params'])+1):\n",
    "    rank = cv.cv_results_['rank_test_score'][i-1]\n",
    "    s = cv.cv_results_['mean_test_score'][i-1]\n",
    "    sd = cv.cv_results_['std_test_score'][i-1]\n",
    "    params = cv.cv_results_['params'][i-1]\n",
    "    print(\"{0}. Mean validation neg log loss: {1:.3f} (std: {2:.3f}) - {3}\".format(\n",
    "        rank,\n",
    "        s,\n",
    "        sd,\n",
    "        params\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 1.0}\n",
      "[[ 3.30586098]]\n"
     ]
    }
   ],
   "source": [
    "# Print the best cross-validation parameters\n",
    "\n",
    "print(cv.best_params_)\n",
    "print(cv.best_estimator_.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1e-06, parameters [[-0.00691736]] and intercept [-0.03892372]\n",
      "C: 0.0001, parameters [[ 0.65118959]] and intercept [-0.78502616]\n",
      "C: 1.0, parameters [[ 3.30586098]] and intercept [-2.39640651]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14c5bb080>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = ['r', 'g', 'b', 'y', 'k', 'c', 'm', 'brown', 'r']\n",
    "lw = 1\n",
    "Cs = [1e-6, 1e-4, 1e0]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for different classifiers')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "labels = []\n",
    "for idx, C in enumerate(Cs):\n",
    "    clf = LogisticRegression(C = C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"C: {}, parameters {} and intercept {}\".format(C, clf.coef_, clf.intercept_))\n",
    "    fpr, tpr, _ = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=lw, color=colors[idx])\n",
    "    labels.append(\"C: {}, AUC = {}\".format(C, np.round(roc_auc, 4)))\n",
    "\n",
    "plt.legend(['random AUC = 0.5'] + labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x14c3f2da0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr, re, _ = precision_recall_curve(y_test, cv.best_estimator_.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(re, pr)\n",
    "plt.title('PR Curve (AUC {})'.format(auc(re, pr)))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mat_idx</th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "      <td>0.223607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "      <td>0.545545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "      <td>0.670820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mat_idx  test_id                                          question1  \\\n",
       "0        0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2        2  What but is the best way to send money from Ch...   \n",
       "3        3        3                        Which food not emulsifiers?   \n",
       "4        4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2   cos_sim  \n",
       "0  Why did Microsoft choose core m3 and not core ...  0.223607  \n",
       "1        How much cost does hair transplant require?  0.545545  \n",
       "2                      What you send money to China?  0.577350  \n",
       "3                                  What foods fibre?  0.288675  \n",
       "4                     How their can I start reading?  0.670820  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df_submit = pd.read_csv(\"input/test_with_cosine_v0.csv\")\n",
    "except OSError:\n",
    "    df_submit['cos_sim'] = df_submit.apply(lambda row: gen_cosine_sim(row['question1'],\n",
    "                                                                  row['question2'],\n",
    "                                                                  vectorizer), axis=1)\n",
    "\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.356403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380897</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.191360</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.200489</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.456020</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.275905</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.512815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.303443</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate  test_id\n",
       "0      0.160224        0\n",
       "1      0.356403        1\n",
       "2      0.380897        2\n",
       "3      0.191360        3\n",
       "4      0.456020        4\n",
       "5      0.200489        5\n",
       "6      0.456020        6\n",
       "7      0.275905        7\n",
       "8      0.512815        8\n",
       "9      0.303443        9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrained = cv.best_estimator_.fit(X, y)\n",
    "\n",
    "X_submission = scaler.transform(df_submit[['cos_sim']])\n",
    "\n",
    "y_submission = retrained.predict_proba(X_submission)[:,1]\n",
    "\n",
    "submission = pd.DataFrame({'test_id': df_submit['test_id'], 'is_duplicate': y_submission})\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_v0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
