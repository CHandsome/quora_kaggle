{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "cosine_sim_feaure.gz\n",
      "sample.rtf\n",
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "import matplotlib.pylab as plt\n",
    "from numpy import linalg as LA\n",
    "%matplotlib\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform, Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of base training File =  (404290, 6)\n",
      "Shape of base training data after cleaning =  (404288, 6)\n",
      "Shape of base training File =  (2345796, 3)\n",
      "Shape of base training data after cleaning =  (2345790, 3)\n",
      "['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_data(path_to_file):\n",
    "    df = pd.read_csv(path_to_file)\n",
    "    print (\"Shape of base training File = \", df.shape)\n",
    "    # Remove missing values and duplicates from training data\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"Shape of base training data after cleaning = \", df.shape)\n",
    "    return df\n",
    "\n",
    "df_train = read_data(\"input/train.csv\")\n",
    "# df_train, df_test = train_test_split(df, test_size = 0.10)\n",
    "# df_train = df_train.reset_index(drop=True)\n",
    "# df_train = df_train.reset_index()\n",
    "# df_train = df_train.rename(columns = {'index':'mat_idx'})\n",
    "\n",
    "df_submit = read_data(\"input/test.csv\")\n",
    "df_submit = df_submit.reset_index(drop=True)\n",
    "df_submit = df_submit.reset_index()\n",
    "df_submit = df_submit.rename(columns = {'index': 'mat_idx'})\n",
    "\n",
    "\n",
    "# Print the column names\n",
    "print (df_train.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words feature\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words feature\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "# Use this as \"stop_words\" arg if include stopwords\n",
    "# stopwords.words('english')\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "# For now assume stop-words are not discounted. No terms are thresholded. \n",
    "vectorizer = CountVectorizer(analyzer = stemmed_words,   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             ngram_range = (1,2), \\\n",
    "                             max_features = 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Set Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# cos_feature_vec = np.zeros((df_train.shape[0],1))\n",
    "\n",
    "def gen_cosine_sim(s1, s2, vectorizer):\n",
    "    try:\n",
    "        features = vectorizer.fit_transform([s1, s2])\n",
    "        similarities = cosine_similarity(features)\n",
    "        return similarities[0,1]\n",
    "#         cos_feature_vec[idx,0] = similarities[0,1]\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "# for idx, row in df_train.iterrows():\n",
    "#     if (not idx % 100000):\n",
    "#         print(\"Generated feature for %d entries\" % (idx))\n",
    "#     try:\n",
    "#         features = vectorizer.fit_transform([row['question1'], row['question2']])\n",
    "#         similarities = cosine_similarity(features)\n",
    "#         cos_feature_vec[idx,0] = similarities[0,1]\n",
    "#     except:\n",
    "#         print(row['question1'])\n",
    "#         print(row['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optionally write the cosine similarity feature vector to compressed file for storage\n",
    "# np.savetxt(\"input/cosine_sim_feaure.gz\",cos_feature_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Feature Generated...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((323430, 1), (80858, 1), (323430,), (80858,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_train['cos_sim'] = df_train.apply(lambda row: gen_cosine_sim(row['question1'],row['question2'],vectorizer), axis=1)\n",
    "\n",
    "# cos_feature_vec.T[0].tolist()\n",
    "\n",
    "print(\"Cosine Similarity Feature Generated...\")\n",
    "\n",
    "scaler = MinMaxScaler().fit(df_train[['cos_sim']])\n",
    "X = scaler.transform(df_train[['cos_sim']])\n",
    "\n",
    "y = df_train['is_duplicate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=37)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [1e-06, 0.001, 1.0], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "grid = {\n",
    "    'C': [1e-6, 1e-3, 1e0],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "cv = GridSearchCV(clf, grid, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Mean validation neg log loss: -0.693 (std: 0.000) - {'C': 1e-06, 'penalty': 'l1'}\n",
      "5. Mean validation neg log loss: -0.690 (std: 0.000) - {'C': 1e-06, 'penalty': 'l2'}\n",
      "3. Mean validation neg log loss: -0.594 (std: 0.001) - {'C': 0.001, 'penalty': 'l1'}\n",
      "4. Mean validation neg log loss: -0.600 (std: 0.001) - {'C': 0.001, 'penalty': 'l2'}\n",
      "1. Mean validation neg log loss: -0.592 (std: 0.001) - {'C': 1.0, 'penalty': 'l1'}\n",
      "2. Mean validation neg log loss: -0.592 (std: 0.001) - {'C': 1.0, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(cv.cv_results_['params'])+1):\n",
    "    rank = cv.cv_results_['rank_test_score'][i-1]\n",
    "    s = cv.cv_results_['mean_test_score'][i-1]\n",
    "    sd = cv.cv_results_['std_test_score'][i-1]\n",
    "    params = cv.cv_results_['params'][i-1]\n",
    "    print(\"{0}. Mean validation neg log loss: {1:.3f} (std: {2:.3f}) - {3}\".format(\n",
    "        rank,\n",
    "        s,\n",
    "        sd,\n",
    "        params\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l1'}\n",
      "[[ 3.30629813]]\n"
     ]
    }
   ],
   "source": [
    "# Print the best cross-validation parameters\n",
    "\n",
    "print(cv.best_params_)\n",
    "print(cv.best_estimator_.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1e-06, parameters [[-0.00691736]] and intercept [-0.03892372]\n",
      "C: 0.0001, parameters [[ 0.65118959]] and intercept [-0.78502616]\n",
      "C: 1.0, parameters [[ 3.30586098]] and intercept [-2.39640651]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1179a34a8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = ['r', 'g', 'b', 'y', 'k', 'c', 'm', 'brown', 'r']\n",
    "lw = 1\n",
    "Cs = [1e-6, 1e-4, 1e0]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for different classifiers')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "labels = []\n",
    "for idx, C in enumerate(Cs):\n",
    "    clf = LogisticRegression(C = C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"C: {}, parameters {} and intercept {}\".format(C, clf.coef_, clf.intercept_))\n",
    "    fpr, tpr, _ = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=lw, color=colors[idx])\n",
    "    labels.append(\"C: {}, AUC = {}\".format(C, np.round(roc_auc, 4)))\n",
    "\n",
    "plt.legend(['random AUC = 0.5'] + labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x120ae1198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr, re, _ = precision_recall_curve(y_test, cv.best_estimator_.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(re, pr)\n",
    "plt.title('PR Curve (AUC {})'.format(auc(re, pr)))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submit['cos_sim'] = df_submit.apply(lambda row: gen_cosine_sim(row['question1'],row['question2'],vectorizer), axis=1)\n",
    "\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-253bcac7dd80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
